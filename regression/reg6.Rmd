---
title: "HW4STA4210"
author: "Eric Brewster"
date: "2024-04-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r RKO data}
rko.dat <- read.csv("https://www.stat.ufl.edu/~winner/data/rko_film_19301941.csv")
attach(rko.dat); names(rko.dat)
totCost <- distCost+prodCost
```

```{r RKO 1a}
RKOmodel <- lm(totRev ~ totCost)
summary(RKOmodel)
(sigma(RKOmodel))
```
Fitted equation: totRev = -4.93661 + 1.07328(totCost)
Estimated standard errors: intercept is 42.31330, totCost is 0.04411
Estimate of sigma (residual standard error): 293.4962


```{r RKO 1b}
fittedValues <- fitted(RKOmodel)
residuals <- residuals(RKOmodel)
absResiduals <- abs(residuals)
squaredResiduals <- residuals^2

plot(fittedValues, residuals, xlab = "Fitted values", ylab = "Residuals",
     main = "Residuals vs Fitted Values")

plot(fittedValues, absResiduals, xlab = "Fitted values", ylab = "Absolute Residuals",
     main = "Absolute Residuals vs Fitted Values")

plot(fittedValues, squaredResiduals, xlab = "Fitted values", ylab = "Squared Residuals",
     main = "Squared Residuals vs Fitted Values")

```


```{r RKO 1c}
(cor(absResiduals, fittedValues))
(cor(squaredResiduals, fittedValues))
```

```{r RKO 1d}

```


```{r RKO 1e}
library(nlme)
mod.EGLS <- gls(totRev ~ I(totCost), method="ML", correlation=corARMA(p=1), data=rko.dat)
mod.OLS1 <- gls(totRev ~ I(totCost), method="ML", data=rko.dat)

summary(mod.EGLS)
anova(mod.OLS1, mod.EGLS)
```




```{r RKO 1f}
summary(mod.OLS1)
summary(mod.EGLS)
anova(mod.OLS1, mod.EGLS)
```


```{r}
detach(rko.dat)
```


```{r software data}
softwareData <- read.csv("C:/Users/14048/Downloads/software2.csv")
attach(softwareData); names(softwareData)
softwareModel <- lm(effortProj ~ sizeProj)
```


```{r software 2a}
summary(softwareModel)
rstudent(softwareModel) 
influence.measures(softwareModel) #  hat values, DFFITS, Cooks D, and DFBETAS
par(mfrow=c(2,2))
plot(softwareModel)
```
Do any projects stand out as outliers or influential cases? Specifically give your “critical” cut-off value for each measure. 10 and 20

Using the criteria in influence_r.txt, 10 is flagged as influential because abs/(1-covratio) (~0.98) is larger than 3xk/(n-k) (0.333) AND 20 is flagged as influential because the hat value (0.4794) is greater than 3*k/n (0.3)



```{r software 2b}
library(quantreg)
software.lad <- rq(effortProj ~ sizeProj,0.5)
summary(software.lad)
confint(softwareModel)
```
Point Estimates: OLS is 2.7471 sizeProj and 364.0792 intercept, LAD is 2.80015 sizeProj and 303.65130 intercept
95% CI OLS: (0.9434507, 4.550663) sizeProj and (-1031.1927360, 1759.351041) intercept
95% CI LAD: (0.86154, 2.91667) sizeProj and (-20.17679, 450.98412) intercept

The point estimates are similar, but the 95% confidence intervals appear significantly larger for the OLS method.



```{r software 2c}
plot(effortProj ~ sizeProj, pch=19, xlab="effortProj", ylab="sizeProj",
  main="Software Model Hours (Y) and Function Points (X)", cex=0.65)
abline(softwareModel, col="blue", lwd=2)
abline(software.lad, col="darkred", lwd=2)
legend("bottomright", c("Data", "OLS", "LAD"), pch=c(19,NA,NA),
   col=c("black","blue","darkred"),  lwd=c(NA,2,2))
```

```{r}
detach(softwareData)
```



```{r miami temp data}
miamiTempData <- read.csv("C:/Users/14048/Downloads/miami_temp.csv")
attach(miamiTempData); names(miamiTempData)
```

```{r miami temp 3a}
miamiModel <- lm(aveTemp ~ year_1970)
summary(miamiModel)
```


```{r miami temp 3b}
plot(resid(miamiModel), type="o", xlab="Year-1970", ylab="Residual")
abline(h=0, col="red", lwd=2)
```


```{r miami temp 3c}
library(car)
durbinWatsonTest(miamiModel)
```
Test statistic is 1.52825 and p-value is 0.064

```{r miami temp 3d}
e.ols <- resid(miamiModel)
n <- length(e.ols)
(r.CO <- sum(e.ols[2:n]*e.ols[1:(n-1)]) / sum(e.ols[2:n]^2))

Yt <- aveTemp[2:n] - r.CO*aveTemp[1:(n-1)]
Xt <- year_1970[2:n] - r.CO*year_1970[1:(n-1)]

miami.CO <- lm(Yt ~ Xt)
summary(miami.CO)
durbinWatsonTest(miami.CO)

SSE.CO <- deviance(miami.CO)
Xtbar.CO <- mean(Xt)
SS_XXt.CO <- sum((Xt-Xtbar.CO)^2)

summary(miami.CO)$coef

b0p <- summary(miami.CO)$coef[1,1]
b1p <- summary(miami.CO)$coef[2,1]
se.b0p <- summary(miami.CO)$coef[1,2] 
se.b1p <- summary(miami.CO)$coef[2,2]

b0.CO <- b0p/(1-r.CO)
s.b0.CO <- se.b0p/(1-r.CO)
b1.CO <- b1p
s.b1.CO <- se.b1p

co.coef.out0 <- c(b0.CO, s.b0.CO)
co.coef.out1 <- c(b1.CO, s.b1.CO)
co.coef.out <- rbind(co.coef.out0, co.coef.out1)
colnames(co.coef.out) <- c("CO Estimate", "CO Std Err")
rownames(co.coef.out) <- c("Intercept", "Year_1970")
round(co.coef.out, 3)
```
CO Intercept B0: Estimate is 75.660, error is 0.277 
CO Year_1970 B1: Estimate is 0.054, error is 0.009


```{r miami temp 3e}
r.HL <- seq(.01,.99,.01)
SSE.HL <- rep(0, length(r.HL))

for (i1 in 1:length(r.HL)) {
  Y.HL <- aveTemp[2:n] - r.HL[i1]*aveTemp[1:(n-1)]
  X.HL <- year_1970[2:n] - r.HL[i1]*year_1970[1:(n-1)]
  SSE.HL[i1] <- deviance(lm(Y.HL ~ X.HL))
}

(r.HL.min <- r.HL[which.min(SSE.HL)])
(SSE.HL.min <- SSE.HL[which.min(SSE.HL)])

Yt.HL.min <- aveTemp[2:n] - r.HL.min*aveTemp[1:(n-1)]
Xt.HL.min <- year_1970[2:n] - r.HL.min*year_1970[1:(n-1)]

Xtbar.HL <- mean(Xt.HL.min)
SS_XXt.HL <- sum((Xt.HL.min-Xtbar.HL)^2)

miami.HL <- lm(Yt.HL.min ~ Xt.HL.min)
durbinWatsonTest(miami.HL)

b0pHL <- summary(miami.HL)$coef[1,1]
b1pHL <- summary(miami.HL)$coef[2,1]
se.b0pHL <- summary(miami.HL)$coef[1,2] 
se.b1pHL <- summary(miami.HL)$coef[2,2] 

b0.HL <- b0pHL/(1-r.HL.min)
s.b0.HL <- se.b0pHL/(1-r.HL.min)
b1.HL <- b1pHL
s.b1.HL <- se.b1pHL

hl.coef.out0 <- c(b0.HL, s.b0.HL)
hl.coef.out1 <- c(b1.HL, s.b1.HL)
hl.coef.out <- rbind(hl.coef.out0,hl.coef.out1)
colnames(hl.coef.out) <- c("HL Estimate", "HL Std Err")
rownames(hl.coef.out) <- c("Intercept", "Year_1970")
round(hl.coef.out, 3)
```
HL Intercept B0: Estimate is 75.659, error is 0.281 
HL Year_1970 B1: Estimate is 0.054, error is 0.009


```{r miami temp 3f}
(n <- length(aveTemp))
(X.new <- 51)
(X.new.t.CO <- X.new - r.CO * year_1970[n])
(X.new.t.HL <- X.new - r.HL.min * year_1970[n])

(e_n.CO <- aveTemp[n] - (b0.CO + b1.CO*year_1970[n]))
(e_n.HL <- aveTemp[n] - (b0.HL + b1.HL*year_1970[n]))

(F.CO <- b0.CO + b1.CO*X.new + r.CO*e_n.CO)
(F.HL <- b0.HL + b1.HL*X.new + r.HL.min*e_n.HL)

MSE.CO <- SSE.CO/(n-3)
MSE.HL <- SSE.HL.min/(n-3)

s2_pred.CO <- MSE.CO*(1 + 1/(n-1) + (X.new.t.CO-Xtbar.CO)^2/SS_XXt.CO)
s2_pred.HL <- MSE.HL*(1 + 1/(n-1) + (X.new.t.HL-Xtbar.HL)^2/SS_XXt.HL)

CO.PI <- cbind(F.CO, F.CO - qt(.975, n-3)* sqrt(s2_pred.CO), 
                     F.CO + qt(.975, n-3)* sqrt(s2_pred.CO))
HL.PI <- cbind(F.HL, F.HL - qt(.975, n-3)* sqrt(s2_pred.HL), 
                     F.HL + qt(.975, n-3)* sqrt(s2_pred.HL))

all.PI <- rbind(CO.PI, HL.PI) 
colnames(all.PI) <- c("Forecast", "Lower", "Upper")
rownames(all.PI) <- c("Cochrane-Orcutt", "Hildreth-Lu")
round(all.PI, 4)
```
Forecast, (lower, upper)
CO: 78.6066, (77.0468, 80.1664)
HL: 78.6176, (77.0579, 80.1774)


```{r}
detach(miamiTempData)
```

