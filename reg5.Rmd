---
title: "HW3STA4210"
author: "Eric Brewster"
date: "2024-03-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Problem 1
```{r data mortgage}
hw3.dat <- read.table("http://www.stat.ufl.edu/~winner/data/myield1.dat",
         header=F,col.names=c("cityid","Y","X1","X2","X3","X4","X5","X6"))
attach(hw3.dat); names(hw3.dat)
```

```{r 1a fit model}
model <- lm(Y ~ X1 + X2 + X3 + X4 + X5 + X6)
```

### Problem 1ai
```{r 1ai}
summary(model)
```
What proportion of variation in Y is “explained” by the
independent variables? 

87.06% of variation is explained by the independent variables, given the multiple R-squared is 0.8706.

### Problem 1aii
```{r 1aii}
summary(model)
```

### Problem 1aiii
```{r 1aiii}
drop1(model, test = "F")
```
The F-tests here are equivalent to the t-tests from part aii in that the only two variables near the 0.05 significance level are X1 and X3. The Pr(>|t|) and Pr(>F) values are the same for each variable. For example, though the t-value and f-value are different, X1's p-value is 0.0515.

### Problem 1b
```{r 1b}
model2 <- lm(Y ~ X1 + X3 + X4)
summary(model2)
anova(model2, model)
```

### Problem 1c
```{r 1c}
modelX1 <- lm(Y ~ X1)
(SSR_X1 <- anova(modelX1)["X1", "Sum Sq"])

modelX1X3 <- lm(Y ~ X1 + X3)
#anova(modelX1X3)
SSR_X1X3 <- anova(modelX1X3)["X1", "Sum Sq"] + anova(modelX1X3)["X3", "Sum Sq"]
(SSR_X3givenX1 <- SSR_X1X3 - SSR_X1)

modelX1X3X4 <- lm(Y ~ X1 + X3 + X4)
#anova(modelX1X3X4)
SSR_X1X3X4 <- anova(modelX1X3X4)["X1", "Sum Sq"] + anova(modelX1X3X4)["X3", "Sum Sq"] +
  anova(modelX1X3X4)["X4", "Sum Sq"]
(SSR_X4givenX1X3 <- SSR_X1X3X4 - SSR_X1X3)

#anova(model)
SSR_All <- anova(model)["X1", "Sum Sq"] + anova(model)["X2", "Sum Sq"] +
  anova(model)["X3", "Sum Sq"] + anova(model)["X4", "Sum Sq"] + anova(model)["X5", "Sum Sq"] +
  anova(model)["X6", "Sum Sq"]
(SSR_X2X5X6givenX1X3X4 <- SSR_All - SSR_X1X3X4)
```

SSR(X1) = 0.5546717
SSR(X3|X1) = 0.1021539
SSR(X4|X1,X3) = 0.07582602
SSR(X2,X5,X6|X1,X3,X4) = 0.006122416

### Problem 1d
```{r 1d}
(R2_Y1 <- summary(modelX1)$r.squared)

#R2_Y3givenY1 is SSRX3givenX1 / SSEX1
(R2_Y3givenY1 <- (SSR_X3givenX1 / anova(modelX1)["Residuals", "Sum Sq"]))

#R2_Y4givenY1Y3 is SSRX4givenX1X3 / SSEX1X3
(R2_Y4givenY1Y3 <- (SSR_X4givenX1X3 / anova(modelX1X3)["Residuals", "Sum Sq"]))

#R2_Y2Y5Y6givenY1Y3Y4 is SSR_X2X5X6givenX1X3X4 / SSEX1X3X4
(R2_Y2Y5Y6givenY1Y3Y4 <- (SSR_X2X5X6givenX1X3X4 / anova(modelX1X3X4)["Residuals", "Sum Sq"]))
```
R-squared Y1 = 0.6536486
R-squared Y3|1 = 0.3475732
R-squared Y4|13 = 0.3954375
R-squared Y256|134 = 0.05281305

### Problem 1e
```{r 1e}
cor(hw3.dat[,-1])
```
Of the 6 predictors, which has the highest correlation with Y (not controlling for the other predictors). What might this be evident of (see parts a.ii, a.iii)?
The predictor with the highest correlation to Y is X1. As X1 also had the lowest p-value (very close to 0.05), this kight be evident that X1 is the most closely related to Y.


```{r}
detach(hw3.dat)
```

# Problem 2
```{r 2 data}
ballisticData <- read.csv("C:/Users/14048/Downloads/ballistic1.csv",
                        header=T,col.names=c("bulletType","layers","V50","Sharp","FSP","V50Csq"))
attach(ballisticData); names(ballisticData)
```


### Problem 2a
```{r 2a}
ballisticModel1 <- lm(V50Csq ~ layers)
ballisticModel2 <- lm(V50Csq ~ layers + Sharp + FSP)
ballisticModel3 <- lm(V50Csq ~ layers + Sharp + FSP + (layers * Sharp) + (layers * FSP))
summary(ballisticModel1)
anova(ballisticModel1)
summary(ballisticModel2)
anova(ballisticModel2)
summary(ballisticModel3)
anova(ballisticModel3)
```
MODEL 1: V50 = Beta0 + Beta1*Layers
Fitted Equation: 4.10651 + 0.94937(Layers)
SSR: 3645.4
SSE: 120
R-Squared: 0.9681

MODEL 2: V50 = Beta0 + Beta1xLayers + Beta2xSharp + Beta3xFSP
Fitted Equation: 1.5880 + 0.9514(Layers) + 3.9482(Sharp) + 3.3681(FSP)
SSR: 3718.9
SSE: 46.4
R-Squared: 0.9877

MODEL 3: V50 = Beta0 + Beta1xLayers + Beta2xSharp + Beta3xFSP + Beta4(LayersXSharp)
  +Beta5(LayersxFSP)
Fitted Equation: 3.64332 + 0.85469(Layers) + 0.76866(Sharp) + 0.49887(FSP) + 
  0.14962(LayersXSharp) + 0.13697(LayersxFSP)
SSR: 3737.1
SSE: 28.2
R-Squared: 0.9925


### Problem 2b
```{r 2b}
anova(ballisticModel1, ballisticModel2)
```

### Problem 2c
```{r 2c}
anova(ballisticModel2, ballisticModel3)
```


```{r}
detach(ballisticData)
```

# Problem 3
```{r 3 data}
golfData <- read.csv("C:/Users/14048/Downloads/lpga2022.csv",
                        header=T,col.names=c("Golfer","Nation","Region","fairways","fairAtt","fairPct","totPutts","totRounds","avePutts","greenReg","totPrize","events","driveDist","sandSaves","sandAtt","sandPct"))
attach(golfData); names(golfData)
```

### Problem 3a
```{r 3a}
yGolfData <- log(totPrize/events)
golfModel1 <- lm(yGolfData ~ fairPct + avePutts + greenReg + driveDist + sandPct + (sandAtt/totRounds))
summary(golfModel1)
```
Significant at the 0.05 level to average putts and greens in regulation.

### Problem 3b
```{r 3b}
summary(golfModel1)$r.squared
```
77.66 percent of the variation of the total variation in Y is explained by the full set of predictors.

### Problem 3c
```{r 3c}
(step(golfModel1))
```
The variables included in the "best" model based on Stepwise regression are fairPct, avePutts, greenReg, and sandAtt.

### Problem 3d
```{r 3d}
library(leaps)
allPossible <- regsubsets(yGolfData ~ fairPct + avePutts + greenReg + driveDist + sandPct + (sandAtt/totRounds), data = golfData, method = "exhaustive", really.big = TRUE, nvmax = 6)
bestModel <- which.min(summary(allPossible)$bic)
(bestBIC <- coef(allPossible, id = bestModel))
```
With all possible regressions, the best predictors included based on BIC are avePutts and greenReg.

### Problem 3e
```{r 3e}
library(caret)
set.seed(88970542)
ctrl <- trainControl(method = "cv", number = 10)

fullModel <- train(
  x = golfData[, c("fairPct", "avePutts", "greenReg", "driveDist", "sandPct", "sandAtt", "totRounds")], 
  y = yGolfData,
  method = "lm",  
  trControl = ctrl)

bestModel <- train(
  x = golfData[, c("fairPct", "avePutts", "greenReg", "sandAtt")],
  y = yGolfData,
  method = "lm",
  trControl = ctrl)

compareModels <- resamples(list(FullModel = fullModel, BestModelStep = bestModel))
summary(compareModels)
```
The full model has lower mean and median MAE and RMSE values (lower errors), but the best stepwise model has a higher mean and median R-squared value. So the best stepwise model has more predictive accuracy, but the full model's lower r-squared may better fit the data (explain more of the variation in the data).


```{r}
detach(golfData)
```



